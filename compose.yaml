# =============================================================================
# Docker Compose Configuration for Collectes EFS
# =============================================================================

# Shared configuration templates
x-common-environment: &common-environment
  RABBITMQ_URL: amqp://efs_rq:rq_efs@rabbitmq:5672/

x-get-service-base: &get-service-base
  build: 
    context: .
    dockerfile: ./collecte-info/Dockerfile
  environment: *common-environment
  volumes: 
    - ./collecte-info/data:/app/data

# =============================================================================
# Services
# =============================================================================

services:
  # ---------------------------------------------------------------------------
  # Infrastructure Services
  # ---------------------------------------------------------------------------
  
  rabbitmq:
    image: rabbitmq:4-management
    ports:
      - "5672:5672"   # AMQP port
      - "15672:15672" # Management UI
    environment:
      RABBITMQ_DEFAULT_USER: efs_rq
      RABBITMQ_DEFAULT_PASS: rq_efs
    restart: unless-stopped
    volumes:
      - rabbitmq_data:/var/lib/rabbitmq
    networks:
      - crawler_network

  # ---------------------------------------------------------------------------
  # Application Services
  # ---------------------------------------------------------------------------
  
  crawler:
    build: ./crawler/
    command: main.py --headless --keep-alive
    depends_on:
      - rabbitmq
    environment: *common-environment
    restart: unless-stopped
    networks:
      - crawler_network

  # ---------------------------------------------------------------------------
  # Data Collection Services
  # ---------------------------------------------------------------------------
  
  consumer:
    <<: *get-service-base
    command: get_schedules.py --listen
    depends_on:
      - rabbitmq
      - crawler
    restart: unless-stopped
    networks:
      - crawler_network

  get-collections:
    <<: *get-service-base
    command: get_collections.py

  get-locations:
    <<: *get-service-base
    command: get_locations.py --force

  get-schedules:
    <<: *get-service-base
    command: get_schedules.py
    depends_on:
      - rabbitmq
      - crawler
    networks:
      - crawler_network

  # ---------------------------------------------------------------------------
  # Database Services
  # ---------------------------------------------------------------------------
  
  postgres:
    image: postgres
    environment:
      POSTGRES_DB: efs_db
      POSTGRES_USER: efs_user
      POSTGRES_PASSWORD: efs_password
    restart: always
    volumes:
      - ./data/postgres:/var/lib/postgresql/data
    ports:
      - 5432:5432
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U efs_user -d efs_db"]
      interval: 10s
      timeout: 5s
      retries: 5

  adminer:
    image: adminer
    ports:
      - 8080:8080
    restart: always
    depends_on:
      - postgres

# =============================================================================
# Volumes & Networks
# =============================================================================

volumes:
  rabbitmq_data:
    driver: local

networks:
  crawler_network:
    driver: bridge